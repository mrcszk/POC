{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Filtracja Non-Local Means\n",
    "\n",
    "## Definicja\n",
    "\n",
    "Kolejny \"poziom wtajemniczenia\" w zagadnienie filtracji obrazów to metoda Non-Local Means (NLM).\n",
    "Została ona zaproponowana w pracy *A non-local algorithm for image denoising* autorstwa Antoni Buades, Bartomeu Coll, i Jean Michel Morel na konferencji CVPR w 2005 roku.\n",
    "\n",
    "Filtr NLM dany jest zależnością:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{I}(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in V(\\mathbf{x})} w(\\mathbf{p},\\mathbf{x})I(\\mathbf{p})\n",
    "\\end{equation}\n",
    "\n",
    "gdzie:\n",
    "- $I$ - obraz wejściowy,\n",
    "- $\\hat{I}$ - obraz wyjściowy (przefiltrowany),\n",
    "- $\\mathbf{x}$ - współrzędne piksela obrazu,\n",
    "- $V(\\mathbf{x})$ - obszar poszukiwań piksela, dla którego przeprowadzana jest filtracja,\n",
    "- $w$ - waga punktu $\\mathbf{p}$ z obszaru poszukiwań.\n",
    "\n",
    "Wróćmy na chwilę do filtracji bilateralnej. Tam waga danego piksela z kontekstu zależała od dwóch czynników - odległości przestrzennej pomiędzy pikselami oraz różnicy w jasności/kolorze pomiędzy pikselami (tzw. przeciwdziedzina).\n",
    "Filtr NLM stanowi uogólnienie tej metody - do obliczania wag nie wykorzystuje się już pojedynczych pikseli ($\\mathbf{p}$ i $\\mathbf{x}$), a lokalne konteksty ($N(\\mathbf{p})$ i $N(\\mathbf{x})$).\n",
    "\n",
    "Waga $w$ dana jest następującą zależnością:\n",
    "\n",
    "\\begin{equation}\n",
    "w(\\mathbf{p},\\mathbf{x}) = \\frac{1}{Z(\\mathbf{x})}\\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n",
    "\\end{equation}\n",
    "\n",
    "gdzie:\n",
    "- \\begin{equation}\n",
    "Z(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in  V(\\mathbf{x})} \\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n",
    "\\end{equation},\n",
    "- $|| \\cdot ||$ - jest normą $L_2$ odległości pomiędzy dwoma kontekstami,\n",
    "- $v$ oznacza mnożenie punktowe kontekstu $N$ przez dwuwymiarową maskę Gaussa o odpowiadających kontekstowi wymiarach,\n",
    "- $\\alpha$ > 0 - parametr sterujący filtracją,\n",
    "- $\\sigma$ - parametr szumu stacjonarnego występującego na obrazie (w przypadku szumu niestacjonarnego, parametr $\\sigma$ musi zostać dopasowany lokalnie tj. $\\sigma = \\sigma(\\mathbf{x})$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza działania\n",
    "\n",
    "Zastanówmy sie teraz jak działa filtra NLM. Najprościej to zrozumieć na rysunku.\n",
    "\n",
    "![Ilustracja NLM](https://raw.githubusercontent.com/vision-agh/poc_sw/master/07_Bilateral/nlm.png)\n",
    "\n",
    "1. Dla rozważanego piksela $\\mathbf{x}$ definiujemy obszar poszukiwań $V(\\mathbf{x})$. Uwaga - obszar poszukiwań ($V$) jest jednostką większą niż otocznie/kontekst ($N$).\n",
    "\n",
    "2. Następnie, dla każdego z pikseli $\\mathbf{p} \\in  V(\\mathbf{x})$ oraz samego $\\mathbf{x}$ definiujemy otocznie/kontekst odpowiednio $N(\\mathbf{p})$ i $N(\\mathbf{x})$.\n",
    "\n",
    "3. Wracamy do równania definiującego wagę  $w(\\mathbf{p},\\mathbf{x})$, a konkretnie do wyrażenia $|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||$. Przeanalizujmy co ono oznacza. Mamy dwa otoczenia: $N(\\mathbf{p})$ i $N(\\mathbf{x})$. Każde z nich mnożymy przez odpowiadającą maskę Gaussa - funkcja $v$. Otrzymujemy dwie macierze, które odejmujemy od siebie punktowo. Następnie obliczamy kwadrat z normy ($L_2$ definiujemy jako $||X||_2 = \\sqrt{\\sum_k|X_k|^2}$. Otrzymujemy zatem jedną liczbę, która opisuje nam podobieństwo otoczeń pikseli $\\mathbf{x}$ i $\\mathbf{p}$. Mała wartość oznacza otoczenia zbliżone, duża - różniące się. Ponieważ, z dokładnością do stałych, liczba ta stanowi wykładnik funkcji $e^{-x}$, to ostatecznie waga jest zbliżona do 1 dla otoczeń podobnych, a szybko maleje wraz z malejącym podobieństwem kontekstów.\n",
    "\n",
    "4. Podsumowując. Jak wynika z powyższej analizy filtr NLM to taki filtr bilateralny, w którym zamiast pojedynczych pikseli porównuje się ich lokalne otoczenia. Wpływa to pozytywnie na jakość filtracji, niestety kosztem złożoności obliczeniowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implementacja\n",
    "\n",
    "W ramach zadania należy zaimplementować filtr NLM, ocenić jego działanie w porównaniu do filtra Gaussa i bilateralnego oraz dokonać pomiaru czasu obliczeń (dla trzech wymienionych metod).\n",
    "\n",
    "Jak już się zrozumie jak działa NLM, jego implementacja jest dość prosta.\n",
    "Wartość parametru $\\alpha$ należy dobrać eksperymentalnie.\n",
    "Nie należy także \"przesadzić\" z rozmiarem obszaru poszukiwań (np. 11x11) oraz kontekstu (5x5 lub 3x3).\n",
    "\n",
    "Wskazówki do implementacji:\n",
    "- algorytm sprowadza się do dwóch podwójnych pętli for: zewnętrzne po pikselach, wewnętrzne po kolejnych obszarach przeszukań,\n",
    "- przed realizacją trzeba przemyśleć problem pikseli brzegowych - de facto problemów jest kilka. Po pierwsze nie dla każdego piksela można wyznaczyć pełny obszar przeszukań (tu propozycja, aby filtrację przeprowadzać tylko dla pikseli z pełnym obszarem). Po drugie, ponieważ rozpatrujemy konteksty, to nawet dla piksela o \"pełnym\" obszarze przeszukań, będą istnieć piksele, dla których nie pełnych kontekstów (sugestia - powiększyć obszar przeszukać, tak aby zawierał konteksty). Ostatni problem jest bardziej techniczny/implementacyjny. Jeśli w kolejnych iteracjach \"jawnie\" wytniemy fragment o rozmiarach obszaru przeszukiwań, to znowu pojawi się problem brzegowy - tu można albo wyciąć nieco większy obszar, albo cały czas \"pracować\" na obrazie oryginalnym (\"żonglerka indeksami\").\n",
    "- warto sprawdzać indeksy i rozmiary \"wycinanych\" kontekstów,\n",
    "- wagi wyliczamy w trzech krokach:\n",
    "    - obliczenia dla $N(\\mathbf{x})$ + inicjalizacja macierzy na wagi,\n",
    "    - podwójna pętla, w której przeprowadzamy obliczenia dla kolejnych $N(\\mathbf{p})$ oraz wyliczamy wagi,\n",
    "    - normalizacja macierzy wag oraz końcowa filtracja obszaru w wykorzystaniem wag.\n",
    "- uwaga, obliczenia trochę trwają, nawet dla obrazka 256x256 i względnie niewielkich obszaru przeszukań i kontesktu.\n",
    "\n",
    "Efekt końcowy:\n",
    "- porównanie wyników metod: filtr Gaussa, filtr bilateralny oraz filtr NLM (2-3 zdania komentarza),\n",
    "- porównanie czasu działania powyższych metod (1 zdanie komentarza).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgaussian(size, sigma):\n",
    "    m = n = size\n",
    "    h, k = m//2, n//2\n",
    "    x, y = np.mgrid[-h:h+1, -k:k+1]\n",
    "    g = np.exp(-(x**2 + y**2)/(2*sigma**2))\n",
    "    return g /g.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlm(image, window_size, context_size, alfa=15, sigma=3):\n",
    "    image_copy = image.copy()\n",
    "    X,Y = image.shape\n",
    "    g_f = fgaussian(context_size, 5)\n",
    "    \n",
    "    border = window_size//2 + context_size//2\n",
    "    \n",
    "    for i in range(border, X - border ):\n",
    "        for j in range(border, Y - border):\n",
    "            \n",
    "            x_w_range_up =   i - window_size//2 \n",
    "            x_w_range_down = i + window_size//2 + 1\n",
    "            y_w_range_left =  j - window_size//2 \n",
    "            y_w_range_right = j + window_size//2 + 1\n",
    "            \n",
    "            window = image[x_w_range_up : x_w_range_down, y_w_range_left : y_w_range_right]\n",
    "            X_w, Y_w = window.shape\n",
    "            \n",
    "            N_x = image[i - context_size//2 : i + context_size//2 + 1  , j - context_size//2 : j + context_size//2 + 1]\n",
    "            \n",
    "            matrix_of_exps = np.zeros(window.shape)\n",
    "            \n",
    "#             print(\"N_X\\n\\n\",N_x)\n",
    "            for i_w in range(X_w):\n",
    "                for j_w in range(Y_w):\n",
    "                    x_c_range_up =   i- window_size//2 + i_w - context_size//2 \n",
    "                    x_c_range_down = i- window_size//2 + i_w + context_size//2 + 1\n",
    "                    y_c_range_left =  j- window_size//2 + j_w - context_size//2 \n",
    "                    y_c_range_right = j- window_size//2 + j_w + context_size//2 + 1\n",
    "                    \n",
    "                    context= image[x_c_range_up : x_c_range_down, y_c_range_left : y_c_range_right]\n",
    "                    \n",
    "#================================================================================================================================\n",
    "\n",
    "                    diff = np.dot(N_x, g_f) - np.dot(context, g_f)  \n",
    "                    norm_of_diff = (np.sum(diff**2))**0.5        \n",
    "                    norm_to_2 = norm_of_diff**2\n",
    "                    matrix_of_exps[i_w,j_w]= np.exp( ((-1) * norm_to_2) / (alfa * ((sigma)**2)))\n",
    "#                     print(matrix_of_exps[i_w,j_w])\n",
    "#                     print(\"n_x\\n\",N_x, \"\\ng_f\\n\", g_f, \"\\ncontext\\n\", context )\n",
    "#                     print(\"\\nm1:\\n\", np.dot(N_x, g_f), \"\\nm2\\n\", np.dot(context, g_f))\n",
    "#                     print(\"\\n\\ndiff\\n\",diff)\n",
    "#                     print(\"norm_ofdiff\", norm_of_diff)\n",
    "#                     print(\"normto2\", norm_to_2)\n",
    "#                     print(\"context\\n\\n\",context)\n",
    "                    \n",
    "#             print(matrix_of_exps)\n",
    "            z_x = np.sum(matrix_of_exps)\n",
    "            w_px_matrix = np.zeros(window.shape)\n",
    "        \n",
    "            for i_w in range(X_w):\n",
    "                for j_w in range(Y_w):\n",
    "                    w_px_matrix[i_w, j_w] = (1/z_x) * matrix_of_exps[i_w,j_w] * image[i- window_size//2 + i_w, j- window_size//2 + j_w ]\n",
    "                    \n",
    "#             print(\"\\n\\nz_x\\n\",z_x)\n",
    "#             print(\"\\n\\nmatrix_of_exps\\n\",matrix_of_exps)\n",
    "#             print(\"\\n\\nw_px_matrix\\n\", w_px_matrix)\n",
    "        \n",
    "            value = np.sum(w_px_matrix )\n",
    "            \n",
    "#             print(\"\\n\\norg:\", image[i,j], \"\\nnew:\", value )\n",
    "            image_copy[i,j]= value\n",
    "    return image_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_pixel_fb(window, g_filtr, sigma_r):\n",
    "    X, Y = window.shape\n",
    "    matrix = np.zeros(window.shape)\n",
    "    \n",
    "    for i_w in range(X):\n",
    "        for j_w in range(Y):\n",
    "            middle_i= X//2\n",
    "            middle_j= Y//2\n",
    "            dst_val = ((middle_i - i_w)**2 + (middle_j - j_w)**2)**0.5\n",
    "\n",
    "            gamma = np.exp(((-1)*(dst_val)**2)/(2*(sigma_r)**2))\n",
    "            \n",
    "            matrix[i_w,j_w] = gamma*window[i_w,j_w]*g_filtr[i_w,j_w]\n",
    "    \n",
    "    value = np.sum(matrix) / np.sum(g_filtr)\n",
    "    return value\n",
    "\n",
    "def f_bilateralna(image, window_size, sigma_s, sigma_r):\n",
    "    g_filtr = fgaussian(window_size, sigma_s)\n",
    "    image_copy = image.copy()\n",
    "    X,Y= image.shape\n",
    "    filter_image=np.zeros((X,Y))\n",
    "    \n",
    "    for i in range(window_size//2, X - window_size//2):\n",
    "        for j in range(window_size//2, Y - window_size//2):\n",
    "            x_range_up = i- window_size//2 \n",
    "            x_range_down = i + window_size//2 + 1\n",
    "            y_range_left = j- window_size//2 \n",
    "            y_range_right = j + window_size//2 + 1\n",
    "    \n",
    "            window = image[x_range_up : x_range_down, y_range_left : y_range_right]\n",
    "            value = get_new_pixel_fb(window, g_filtr, sigma_r)\n",
    "            \n",
    "            image_copy[i,j]= value\n",
    "    return image_copy\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_pixel_value(window, g_filtr):\n",
    "    matrix = np.zeros(window.shape)\n",
    "    \n",
    "    for i_w in range(len(window[:])):\n",
    "        for j_w in range(len(window[i_w, :])):\n",
    "            matrix[i_w,j_w] = window[i_w,j_w]*g_filtr[i_w,j_w]\n",
    "    \n",
    "    value = np.sum(matrix) / np.sum(g_filtr)\n",
    "    return value\n",
    "\n",
    "def konwolucja(image, window_size, sigma):\n",
    "    g_filtr = fgaussian(window_size, sigma)\n",
    "    image_copy = image.copy()\n",
    "    X,Y= image.shape\n",
    "    filter_image=np.zeros((X,Y))\n",
    "    \n",
    "    for i in range(window_size//2, X - window_size//2):\n",
    "        for j in range(window_size//2, Y - window_size//2):\n",
    "            x_range_up = i- window_size//2 \n",
    "            x_range_down = i + window_size//2 + 1\n",
    "            y_range_left = j- window_size//2 \n",
    "            y_range_right = j + window_size//2 + 1\n",
    "    \n",
    "            window = image[x_range_up : x_range_down, y_range_left : y_range_right]\n",
    "            value = get_new_pixel_value(window, g_filtr)\n",
    "            \n",
    "            image_copy[i,j]= value\n",
    "    return image_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from timeit import default_timer as timer\n",
    "import math\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"MR_data.mat\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/07_Bilateral/MR_data.mat --no-check-certificate\n",
    "\n",
    "mat = loadmat('MR_data.mat')\n",
    "Input = mat['I_noisy1']        \n",
    "plt.gray()\n",
    "\n",
    "# POMIAR CZASOW\n",
    "\n",
    "start = timer()\n",
    "konw_image=konwolucja(Input, window_size = 3, sigma = 5)\n",
    "end = timer()\n",
    "konw_time=(end - start)\n",
    "\n",
    "start = timer()\n",
    "bilat_image=f_bilateralna(Input, window_size = 3, sigma_s = 5, sigma_r = 3)\n",
    "end = timer()\n",
    "bilat_time=(end - start)\n",
    "\n",
    "start = timer()\n",
    "nlm_image=nlm(Input, window_size = 11, context_size = 3)    \n",
    "end = timer()    \n",
    "nlm_time=(end - start)\n",
    "    \n",
    "    \n",
    "    \n",
    "f, tab = plt.subplots(2,2, figsize=(15,15))\n",
    "tab[0,0].imshow(Input)\n",
    "tab[0,0].axis('off')\n",
    "tab[0,0].set_title('Oryginal')\n",
    "\n",
    "tab[0,1].imshow(nlm_image)\n",
    "tab[0,1].axis('off')\n",
    "tab[0,1].set_title('NLM Time:'+ str(nlm_time))\n",
    "\n",
    "tab[1,0].imshow(konw_image)\n",
    "tab[1,0].axis('off')\n",
    "tab[1,0].set_title('Konwolucja Time:'+ str(konw_time))\n",
    "\n",
    "tab[1,1].imshow(bilat_image)\n",
    "tab[1,1].axis('off')\n",
    "tab[1,1].set_title('Bilateralna Time:'+ str(bilat_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Najlepszy efekt uzyskuje się bezapelacyjnie dla algorytmu nlm. Obraz zarazem jest dość ostry i nie ma na nim zakłóceń. \n",
    "# Pozostałe metody pozbywaja się zakłóceń tlyko w jakimś stopniu a dodatkow bardziej rozmywają obraz.\n",
    "# Niestety wrogiem metody nlm jest czas, który jest wynikiem ogromnej złożoności obliczeniowej - Czas ten jest O WIELE dłuższy niż w pozostałych algorytmach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
